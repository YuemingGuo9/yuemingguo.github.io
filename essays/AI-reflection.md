---
layout: essay
type: essay
title: "AI as a Companion in Software Engineering: A Reflection on ICS 314"
date: 2025-05-11
published: true
labels:
  - AI-reflection
---

### I. Introduction

Artificial Intelligence has rapidly woven itself into modern education. For students in software engineering, tools like ChatGPT and GitHub Copilot have shifted how we approach problem-solving, debug issues, and even write. In ICS 314, I found myself turning to these tools—not to skip the learning, but to enhance it. Whether it was clarifying React component logic or deciphering Prisma migration errors, AI served as both a tutor and a teammate during the semester.

### II. AI in My Coding Workflow

I didn’t start the course relying on AI. In fact, early WODs (Workout of the Day assignments) were manageable enough with traditional problem-solving. But as we moved into more complex tech stacks like Next.js and Prisma, I found that AI could be a powerful support system—if used wisely.

- **Debugging**: Prisma migrations threw some strange errors. ChatGPT helped me understand the concept of “drift” and even explained how `npx prisma migrate reset` worked behind the scenes. This gave me confidence to handle future migration errors with a clear mind.
- **Code Refactoring**: I often asked Copilot for help reformatting async functions or cleaning up repetitive logic. While its suggestions weren’t always perfect, they gave me a starting point to iterate from.
- **Playwright Tests**: One of the toughest challenges was writing stable Playwright tests for our final project. When test behavior diverged between debug mode and headless runs, ChatGPT helped me understand timing issues and async pitfalls. It didn’t fix everything, but it pointed me in the right direction when the error messages didn’t.

### III. AI for Conceptual Understanding

AI also helped me bridge knowledge gaps in HTML, CSS modules, and even database relations. When I didn’t understand how a `useEffect` hook worked or why certain JSX code looked weird, I’d ask ChatGPT to explain it in simpler terms.

That said, I’ve learned that **AI can only reinforce what I’m already trying to learn**. When I blindly copied code without understanding it, it rarely stuck. But when I asked, “What does this function really do?” or “Why is this style not applying?”—that’s when the tool became part of my learning.

### IV. Writing and Documentation

While I didn’t use AI to write full essays or documentation from scratch, I did use it to help organize my thoughts. For example, when preparing a reflection report on AI ethics in computing, I prompted ChatGPT to summarize the source article and suggest an outline. I still wrote the actual reflection myself, but it saved me from information overload.

Similarly, during code documentation, Copilot would sometimes auto-generate comments explaining what each function did. While I reviewed and edited those, they gave me a faster way to keep code understandable—not just for others, but for myself when revisiting it later.

### V. Classroom and Teamwork Use

In group chats or class discussions, I didn’t usually use AI to answer questions, but I did use it to **check my own understanding** before contributing. If someone asked something I wasn’t sure about, I’d consult AI first—not to copy an answer, but to double-check I wasn’t misinforming anyone.

This made me more confident in collaborating with teammates. If I used AI to assist in solving something, I’d say, “This part came from ChatGPT, but I checked and tweaked it.” Being transparent helped us all work more efficiently.

### VI. Challenges and Self-Regulation

There were moments I almost slipped into over-reliance—especially under time pressure. Once, during a timed WOD, I pasted the prompt into ChatGPT and submitted the code it gave me because I was running out of time. It worked, but I didn’t learn much from it.

That experience made me rethink how I use AI. Since then, I’ve made a conscious effort to **treat AI as a guide, not a shortcut**. If I can’t explain what a line of code is doing, then I know I shouldn’t submit it.

### VII. AI in the Bigger Picture

Outside the course, I’ve seen AI used in areas like medical diagnostics, customer service chatbots, and academic research. These examples remind me that AI is not just about “getting help with homework”—it’s shaping the real world. But no matter how powerful it becomes, I believe human oversight and interpretation will always be necessary.

### VIII. Suggestions for Future Courses

ICS 314 already encourages exploration and autonomy, but I think adding an “AI Literacy” module could be helpful. It could show examples of good and bad AI usage, how to validate AI-generated code, and how to ask effective prompts. Just like we learn to use Git or Visual Studio Code, learning to collaborate with AI could be part of the curriculum.

### IX. Conclusion

AI didn’t make me a software engineer this semester—but it made the process a lot less lonely. It gave me a second opinion, a first draft, and sometimes a much-needed nudge when I was stuck. But the learning still had to come from me.

As I move forward, I’ll keep using AI—not to avoid the struggle, but to better understand it. Like any good teammate, it works best when I bring my own effort to the table.

> "AI is not a replacement for thinking—it’s a reminder that thinking is still required."
